import streamlit as st
import google.generativeai as genai
from audiorecorder import audiorecorder
import speech_recognition as sr
from gtts import gTTS
from io import BytesIO
import base64
from pydub import AudioSegment
import shutil
import os

# --- 1. C·∫§U H√åNH API KEY (T·ª∞ ƒê·ªòNG) ---
# Logic: N·∫øu ch·∫°y tr√™n Cloud th√¨ l·∫•y t·ª´ Secrets. N·∫øu ch·∫°y Local th√¨ l·∫•y key c·ª©ng.
try:
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
except:
    # Thay Key c·ªßa b·∫°n v√†o d√≤ng d∆∞·ªõi (d√πng khi ch·∫°y tr√™n m√°y t√≠nh)
    GOOGLE_API_KEY = "AIzaSyDxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

genai.configure(api_key=GOOGLE_API_KEY)

# D√πng b·∫£n 2.5 Flash ƒë·ªÉ ·ªïn ƒë·ªãnh nh·∫•t tr√™n Cloud hi·ªán t·∫°i
model = genai.GenerativeModel('gemini-2.5-flash')

# --- 2. C·∫§U H√åNH FFMPEG ---
# T·ª± ƒë·ªông t√¨m FFmpeg trong h·ªá th·ªëng (cho Cloud Linux v√† Local Windows)
if shutil.which("ffmpeg"):
    AudioSegment.converter = shutil.which("ffmpeg")
else:
    # Fallback: T√¨m file exe c√πng th∆∞ m·ª•c (cho Windows n·∫øu ch∆∞a c√†i v√†o Path)
    AudioSegment.converter = "ffmpeg.exe" 
    AudioSegment.ffmpeg = "ffmpeg.exe"
    AudioSegment.ffprobe = "ffprobe.exe"

# --- 3. KH·ªûI T·∫†O SESSION STATE ---
if "recorder_key" not in st.session_state:
    st.session_state.recorder_key = "0"

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# --- 4. C√ÅC H√ÄM X·ª¨ L√ù ---

def text_to_speech(text):
    """Chuy·ªÉn vƒÉn b·∫£n th√†nh gi·ªçng n√≥i (Anh-Anh) v√† t·ª± ƒë·ªông ph√°t"""
    try:
        tts = gTTS(text=text, lang='en', tld='co.uk') 
        audio_bytes = BytesIO()
        tts.write_to_fp(audio_bytes)
        audio_bytes.seek(0)
        
        audio_base64 = base64.b64encode(audio_bytes.read()).decode()
        audio_html = f"""
            <audio autoplay="true" style="display:none;">
            <source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3">
            </audio>
        """
        st.markdown(audio_html, unsafe_allow_html=True)
    except Exception as e:
        st.error(f"L·ªói TTS: {e}")

def speech_to_text(audio_segment):
    """Chuy·ªÉn AudioSegment th√†nh vƒÉn b·∫£n"""
    r = sr.Recognizer()
    try:
        # Chuy·ªÉn sang WAV (RAM)
        wav_io = BytesIO()
        audio_segment.export(wav_io, format="wav") 
        wav_io.seek(0) 
            
        with sr.AudioFile(wav_io) as source:
            r.adjust_for_ambient_noise(source)
            audio_data = r.record(source)
            text = r.recognize_google(audio_data, language="en-US")
            return text
    except sr.UnknownValueError:
        return None
    except Exception as e:
        st.error(f"L·ªói STT: {e}")
        return None

# --- 5. K·ªäCH B·∫¢N AI ---
system_instruction = """
You are a strict IELTS Speaking Examiner. 
Your GOAL: Test the user's speaking ability naturally.

RULES FOR RESPONSE FORMAT:
1. IF USER MAKES A MISTAKE:
   Output format: [Brief Correction] ||| [Next Question]
   Example: You said "I go". Correct: "I went". ||| What did you do there?

2. IF USER IS CORRECT:
   Output format: [Next Question]
   Example: Interesting. ||| Do you prefer working alone or in a team?

IMPORTANT:
- Use "|||" to separate feedback (text only) and speech (voice).
- The part AFTER "|||" will be spoken by voice. Keep it natural.
- Start with a Part 1 question about Work, Study, or Hobbies.
"""

# Kh·ªüi t·∫°o Chat
if "chat" not in st.session_state:
    st.session_state.chat = model.start_chat(history=[])
    first_resp = st.session_state.chat.send_message(system_instruction)
    initial_text = first_resp.text
    
    if "|||" in initial_text:
        _, q = initial_text.split("|||")
        st.session_state.chat_history.append({"role": "assistant", "content": q.strip()})
        st.session_state.initial_audio = q.strip()
    else:
        st.session_state.chat_history.append({"role": "assistant", "content": initial_text})
        st.session_state.initial_audio = initial_text

# --- 6. GIAO DI·ªÜN ---
st.set_page_config(page_title="IELTS Examiner", page_icon="üá¨üáß")
st.title("üá¨üáß IELTS Speaking Virtual Examiner")
st.caption("Nghe c√¢u h·ªèi -> B·∫•m ghi √¢m ƒë·ªÉ tr·∫£ l·ªùi -> Nh·∫≠n s·ª≠a l·ªói")

# Hi·ªÉn th·ªã l·ªãch s·ª≠
for msg in st.session_state.chat_history:
    role = "üßë‚Äçüíª B·∫°n" if msg["role"] == "user" else "üë®‚Äçüè´ Gi√°m kh·∫£o"
    if role == "üë®‚Äçüè´ Gi√°m kh·∫£o" and "[Feedback]" in msg["content"]:
         st.warning(msg["content"])
    else:
         with st.chat_message(msg["role"]):
            st.write(msg["content"])

# Ph√°t √¢m thanh ch√†o m·ª´ng
if "initial_audio" in st.session_state:
    text_to_speech(st.session_state.initial_audio)
    del st.session_state.initial_audio

st.write("---")

# N√öT GHI √ÇM (RESET KEY)
audio = audiorecorder("Nh·∫•n ƒë·ªÉ tr·∫£ l·ªùi", "ƒêang ghi √¢m...", key=st.session_state.recorder_key)

if len(audio) > 0:
    # 1. STT
    user_text = speech_to_text(audio)
    
    if user_text:
        st.session_state.chat_history.append({"role": "user", "content": user_text})
        
        # 2. G·ª≠i cho AI
        with st.spinner("Gi√°m kh·∫£o ƒëang ch·∫•m ƒëi·ªÉm..."):
            try:
                response = st.session_state.chat.send_message(user_text)
                full_reply = response.text
                
                # 3. T√ÅCH PH·∫¶N S·ª¨A L·ªñI V√Ä C√ÇU H·ªéI
                voice_content = full_reply
                
                if "|||" in full_reply:
                    feedback_part, question_part = full_reply.split("|||")
                    st.session_state.chat_history.append({"role": "assistant", "content": f"[Feedback] {feedback_part.strip()}"})
                    voice_content = question_part.strip()
                    st.session_state.chat_history.append({"role": "assistant", "content": voice_content})
                else:
                    st.session_state.chat_history.append({"role": "assistant", "content": full_reply})
                
                # 4. ƒê·ªåC TO
                text_to_speech(voice_content)
                
            except Exception as e:
                st.error(f"L·ªói AI: {e}")

        # 5. RESET N√öT
        st.session_state.recorder_key = str(int(st.session_state.recorder_key) + 1)
        st.rerun()
    else:
        st.error("Kh√¥ng nghe r√µ. Vui l√≤ng th·ª≠ l·∫°i.")
